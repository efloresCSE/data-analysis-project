[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "yelp-reviews-crime",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Data Analysis Project Using Linear Regression",
    "section": "",
    "text": "The goal of this project is to understand if there is a relationship between the number of yelp reviews and the number of criminal incidents on its associated neighborhood block, and/or if there is a relationship between the overall yelp rating of a public park and the number of criminal incidents on its block. Specifically, I will be examining public parks in the city of San Diego that have had at least one criminal incident in the year 2019. Ultimately, the analysis suggests that a higher yelp rating for a given park slightly positively correlates to a higher number of criminal incidents on its block. Also, the analysis suggests that a higher number of yelp reviews positively correlates to a higher number of criminal incidents on its block."
  },
  {
    "objectID": "about.html#background-and-prior-work",
    "href": "about.html#background-and-prior-work",
    "title": "Data Analysis Project Using Linear Regression",
    "section": "Background and Prior Work",
    "text": "Background and Prior Work\nTo begin, the first thing to understand is the goals of the Parks and Recreation department in San Diego. The San Diego Parks and Recreation Master Plan states that it is their goal to commit to upgrading security and increasing visitor satisfaction to the parks in San Diego. [1] Recently, crime concerns and incidents in the San Diego area have pushed the Parks and Recreation department of San Diego to implement Park curfews [2]. This brings the question of how a visitor’s perceived danger of the parks and its surrounding area impacts their satisfaction towards these parks.\nLooking into yelp reviews of the local parks in San Diego, one can see evidence of user dissatisfaction in the form of low yelp ratings because they feel that some parks and their areas are dangerous or they feel that their well being is not secured. An example of yelp reviews being used to predict a state of a location is in an analysis where yelp review helped predict unhygienic establishments in Seattle [3] This project relates to my study as my goal is to see if there is a correlation between yelp ratings and the state of crime in a local park.\nSome relevant prior work that underwent a similar project analysis was from a student in COGS 108 who tried to identify the relationship between health inspection scores and yelp ratings. [4] This was a sample project given to us by the instructor. This analysis relates to my project as I will also be trying to find a relationship between a measurable factor of a certain location (the number of criminal incidents) and properties of its yelp reviews such as their frequency and the overall rating of a park. We will be utilizing similar techniques from this sample project in this analysis.\nReferences (include links): - 1) https://www.sandiego.gov/complete-communities/parks-master-plan#:~:text=The%20Parks%20Master%20Plan%20aligns,equity%2C%20livability%2C%20and%20connectivity. - 2) https://www.sandiegouniontribune.com/communities/san-diego/story/2020-02-16/park-curfews-on-the-rise-in-san-diego-in-response-to-crime-concerns - 3) https://dho.stanford.edu/wp-content/uploads/WWW_Final.pdf - 4) https://github.com/COGS108/IndividProjects-Sp20/blob/main/FinalProject_michelemurakami.ipynb"
  },
  {
    "objectID": "about.html#loading-data",
    "href": "about.html#loading-data",
    "title": "Data Analysis Project Using Linear Regression",
    "section": "Loading Data",
    "text": "Loading Data\nWe will being by loading the datasets that will be used in our analysis.\n\nyelp_df = pd.read_csv(r\"C:\\Users\\efloresCSE\\Downloads\\yelp_SD_parks.csv\")\ncrime_df = pd.read_csv(r\"C:\\Users\\efloresCSE\\Downloads\\pd_calls_for_service_2019_datasd.csv\", dtype = {'address_number_primary': str,\n                                                                                               'address_dir_primary':str, 'address_road_primary' :str,\n                                                                                                 'address_sfx_primary':str})"
  },
  {
    "objectID": "about.html#checking-our-data",
    "href": "about.html#checking-our-data",
    "title": "Data Analysis Project Using Linear Regression",
    "section": "Checking Our Data",
    "text": "Checking Our Data\n\nyelp_df.head()\n\n\n\n\n\n\n\n\nname\naddress\nphone\nid\nurl\nrating\nreview_count\nlongitude\nlatitude\nis_closed\n\n\n\n\n0\nBalboa Park\n1549 El Prado San Diego, CA 92101\n1.619239e+10\n9M_FW_-Ipx93I36w-_ykBg\nhttps://www.yelp.com/biz/balboa-park-san-diego...\n5.0\n2105\n-117.153150\n32.734502\nFalse\n\n\n1\nCivita Park\n7960 Civita Blvd San Diego, CA 92108\nNaN\n3AEHjqNrTmggA6G9VdhQfg\nhttps://www.yelp.com/biz/civita-park-san-diego...\n4.5\n46\n-117.147278\n32.778315\nFalse\n\n\n2\nWaterfront Park\n1600 Pacific Hwy San Diego, CA 92101\n1.619233e+10\n3unbJeYrn1RmInZGmjp80g\nhttps://www.yelp.com/biz/waterfront-park-san-d...\n4.5\n242\n-117.172479\n32.721952\nFalse\n\n\n3\nTrolley Barn Park\nAdams Ave And Florida St San Diego, CA 92116\nNaN\nPvHxIYrmaiFKdWUDTMDzcg\nhttps://www.yelp.com/biz/trolley-barn-park-san...\n4.5\n102\n-117.143789\n32.762463\nFalse\n\n\n4\nBay View Park\n413 1st St Coronado, CA 92118\nNaN\n6IF4VB9-fkv_F-LBvG8ppQ\nhttps://www.yelp.com/biz/bay-view-park-coronad...\n5.0\n42\n-117.178967\n32.701785\nFalse\n\n\n\n\n\n\n\n\ncrime_df.head()\n\n\n\n\n\n\n\n\nincident_num\ndate_time\nday_of_week\naddress_number_primary\naddress_dir_primary\naddress_road_primary\naddress_sfx_primary\naddress_dir_intersecting\naddress_road_intersecting\naddress_sfx_intersecting\ncall_type\ndisposition\nbeat\npriority\n\n\n\n\n0\nE19010000001\n2019-01-01 00:00:01\n1\n3800\nNaN\nNATIONAL\nAVE\nNaN\nNaN\nNaN\nAU1\nDUP\n441\n1\n\n\n1\nE19010000002\n2019-01-01 00:00:04\n1\n6500\nNaN\nREFLECTION\nDR\nNaN\nNaN\nNaN\n415\nK\n321\n2\n\n\n2\nE19010000003\n2019-01-01 00:00:09\n1\n0\nNaN\n06TH\nAVE\nNaN\nISLAND\nNaN\nFD\nK\n523\n2\n\n\n3\nE19010000004\n2019-01-01 00:00:19\n1\n0\nNaN\nVESTA\nST\nNaN\nMAIN\nNaN\nAU1\nW\n511\n1\n\n\n4\nE19010000005\n2019-01-01 00:00:31\n1\n0\nNaN\n04TH\nAVE\nNaN\nISLAND\nNaN\n586\nCAN\n523\n4"
  },
  {
    "objectID": "about.html#dropping-columns",
    "href": "about.html#dropping-columns",
    "title": "Data Analysis Project Using Linear Regression",
    "section": "Dropping Columns",
    "text": "Dropping Columns\nIn this section, we will be dropping columns that hold data that we will not be using in our analysis.\nWe dropped the following columns from the yelp dataset because\n\nphone, id, url, longitude, latitude\n\nSince we have the address of the park, this extra identifying information is unnecessary.\n\nis_closed\n\nWhether the park is currently closed is not relevant information as we want to analyze the incidents that occurred in 2019.\n\n\nWe dropped the following columns from the crime dataset because\n\nincident_num, date_time, day_of_week, priority\n\nThe exact incident number, priority, day_of_week, or time of day is not important to us, we only care which block the incident took place.\n\naddress_dir_intersecting. address_road_intersecting, address_sfx_intersecting\n\nWe cannot be sure if the incident took place on a park’s block if we only know a cross street.\nThis means we will also have to drop observations that only have cross street information (see the section on cleaning up the crime data).\n\nbeat\n\nWe are already given the block of the incident so the general territory that the police patrolled is redundant.\n\n\n\nyelp_df = yelp_df.drop([\"phone\", \"id\", \"url\", \"longitude\", \"latitude\", \"is_closed\"], axis=1)\ncrime_df = crime_df.drop([\"incident_num\", \"date_time\", \"day_of_week\", \"address_dir_intersecting\",\n                          \"address_road_intersecting\", \"address_sfx_intersecting\", \"beat\", \"priority\"], axis=1)"
  },
  {
    "objectID": "about.html#cleaning-the-crime-data",
    "href": "about.html#cleaning-the-crime-data",
    "title": "Data Analysis Project Using Linear Regression",
    "section": "Cleaning the Crime Data",
    "text": "Cleaning the Crime Data\nWe will drop any observations that have an address number set as 0 as we can not be sure if these incidents took place on a specific block.\n\ncrime_df = crime_df[crime_df.address_number_primary != \"0\"]\n\nWe will also drop any observation that have missing values on the call type or disposition as they will not give us substantial information in clearly knowing if these incidents were verified to be criminal or were cancelled calls.\n\ncrime_df = crime_df.dropna(subset=['call_type'], axis = 0)\ncrime_df = crime_df.dropna(subset=['disposition'], axis = 0)\n\nNext, our goal is to merge the four address columns to make a complete address.\n\ncrime_df = crime_df.fillna(\"\")\ncrime_df = crime_df.assign(block_address = crime_df['address_number_primary'])\n\ncrime_df['block_address'] = crime_df['address_number_primary'] + \" \" + crime_df['address_dir_primary'] + \" \" + crime_df['address_road_primary'] + \" \" + crime_df['address_sfx_primary']\ncrime_df['block_address'] = crime_df['block_address'].str.replace('  ', ' ')\n        \n#Re-order the columns for clarity\ncrime_df = crime_df[['block_address', 'call_type', 'disposition', 'address_number_primary', 'address_dir_primary', 'address_road_primary', 'address_sfx_primary']]\n\nNext, using the disposition information, we will remove any calls for service that are not verified criminal incidents such as those that were canceled or those that were unfounded.\n\n#Remove calls that were cancelled\ncrime_df = crime_df[crime_df.disposition != \"CAN\"]\ncrime_df = crime_df[crime_df.disposition != \"X\"]\ncrime_df = crime_df[crime_df.disposition != \"W\"]\n\n#Remove unfounded service calls\ncrime_df = crime_df[crime_df.disposition != \"U\"]\n\nIn order to merge with our park data, we want to focus on the number of incidents that took place a particular block, so we will make a new data frame object that holds the addresses of the blocks and the number of criminal incidents that took place on those blocks in the year 2019.\n\ncrime_df['criminal_incidents'] = crime_df.groupby('block_address')['block_address'].transform('count')\ncrime_rate_df = pd.concat([crime_df['block_address'], crime_df['criminal_incidents']], axis=1, keys=['block_address', 'criminal_incidents'])\n\n#delete any duplicate observations\ncrime_rate_df = crime_rate_df.drop_duplicates(subset=['block_address'])"
  },
  {
    "objectID": "about.html#clean-yelp-data",
    "href": "about.html#clean-yelp-data",
    "title": "Data Analysis Project Using Linear Regression",
    "section": "Clean Yelp Data",
    "text": "Clean Yelp Data\nThe goal of this section is to obtain the block address of each park. We will obtain this by removing the last three elements of the yelp address (city, state, zip code), and round the address number down.\n\n#Remove zip, city and state info\nyelp_df[\"clean_address\"] = yelp_df[\"address\"].apply(lambda x: \" \".join(x.split()[: -2]))\n\ncities = ['San Diego,','Coronado,','La Jolla,', 'Chula Vista,', 'Oceanside,', 'Carlsbad,', 'El Cajon,', 'Encinitas,',\n                'Poway,', 'La Mesa,', 'Del Mar,', 'San Marcos,', 'National City,', 'Vista,', 'Santee,', 'Julian,', 'Imperial Beach,', \n                'Spring Valley,', 'Alpine,', 'Rancho San Diego,', 'Fallbrook,', 'Lemon Grove,', 'Bonita,', 'Solana Beach,',\n                'Rancho Santa Fe,', 'Lakeside,', 'Ramona,', 'Camp Pendleton North,', 'Jamul,', 'Valley Center,', 'Borrego Springs,', \n                 'Jacumba Hot Springs,', 'Tecate,', 'Bonsall,', 'Potrero,', 'Mount Laguna,', 'Descanso,', 'Campo,', 'Pine Valley,',\n                 'Lake San Marcos,', 'Fairbanks Ranch,', 'Harbison Canyon,', 'Camp Pendeleton South,', 'Boulevard,', 'Crest,',\n                 'Granite Hills,', 'Bostonia,', 'Rainbow,', 'Winter Gardens,', 'Hidden Meadows,']\n\n#go through each observation, if cities match remove it\nfor ind in yelp_df.index:\n    for curr_word in cities:\n        word_list = curr_word.split()\n        size = len(word_list)\n        if(len(yelp_df['clean_address'][ind].split()) &gt;= size):\n            if (word_list == yelp_df['clean_address'][ind].split()[-size:]):\n                yelp_df['clean_address'][ind] = ' '.join(yelp_df['clean_address'][ind].split()[:-size])\n                break\n                \n#round down address numbers\nyelp_df[\"clean_address2\"] = yelp_df[\"address\"].apply(lambda x: \" \".join(x.split()[: 1]))\nyelp_df[\"clean_address\"] = yelp_df[\"clean_address\"].apply(lambda x: \" \".join(x.split()[1:]))\nyelp_df[\"clean_address2\"] = yelp_df[\"clean_address2\"].astype(str)\n\n# # go thorugh and round down numbers\nfor ind in yelp_df.index:\n    if (yelp_df['clean_address2'][ind].isdigit()):\n        yelp_df['clean_address2'][ind] = str(int((int(yelp_df['clean_address2'][ind])/ 100))*100)\n        \n\n# #Concatenate back together\nyelp_df['block_address'] = yelp_df['clean_address2'] + \" \" + yelp_df['clean_address']\n\n# Now that we have the block_address, we can drop our clean_address and clean_address2 columns\nyelp_df = yelp_df.drop([\"clean_address\", \"clean_address2\"], axis=1)\nyelp_df['block_address'] = yelp_df['block_address'].str.upper() \nyelp_df['name'] = yelp_df['name'].str.upper() \n\nFinally we will merge the yelp rating information with the crime rate information by their block address\n\ndf = pd.merge(yelp_df, crime_rate_df, on='block_address')\n\nWe previously noticed that some of the observations from the yelp_SD_parks data are not actually parks, it is impotant that we remove these because, for example, a restaurant with a high rating in an area with a high crime rate can corrupt our analysis.\n\n#Keep all strings that have park in the name\ndf = df[df.name.str.contains(\"PARK\")]\n\nnot_park = ['PARKING', 'PARK-IT-ON-MARKET', 'INN AT THE PARK', 'TOWN PARK BILLAS', 'ENCONTRO NORTH PARK', 'NORTH PARK BEER COMPANY', '619 SPIRITS NORTH PARK',\n           'NORTH PARK OPTOMETRY', 'URBN - NORTH PARK', 'NORTH PARK NURSERY', 'PARKSIDE TERRACE', 'UNION COWORK NORTH PARK',\n           'COLINA PARK GOLF COURSE']\n\n#Remove all entries with names that are not parks\nfor curr_word in not_park:\n    df = df[~df.name.str.contains(curr_word)]\n\n#reset the index\ndf.reset_index(drop=True, inplace=True)"
  },
  {
    "objectID": "about.html#analysis-using-linear-regression",
    "href": "about.html#analysis-using-linear-regression",
    "title": "Data Analysis Project Using Linear Regression",
    "section": "Analysis using Linear Regression",
    "text": "Analysis using Linear Regression\n\n#create thje model\noutcome, predictors = patsy.dmatrices('criminal_incidents ~ rating', df)\nmod = sm.OLS(outcome, predictors)\n\n## fit the model\nres = mod.fit()\n\n## look at the results\nprint(res.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:     criminal_incidents   R-squared:                       0.009\nModel:                            OLS   Adj. R-squared:                 -0.003\nMethod:                 Least Squares   F-statistic:                    0.7681\nDate:                Thu, 15 Aug 2024   Prob (F-statistic):              0.383\nTime:                        19:50:51   Log-Likelihood:                -479.16\nNo. Observations:                  88   AIC:                             962.3\nDf Residuals:                      86   BIC:                             967.3\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     13.5702     34.616      0.392      0.696     -55.244      82.385\nrating         7.6419      8.719      0.876      0.383      -9.691      24.975\n==============================================================================\nOmnibus:                       76.462   Durbin-Watson:                   2.020\nProb(Omnibus):                  0.000   Jarque-Bera (JB):              475.420\nSkew:                           2.854   Prob(JB):                    5.81e-104\nKurtosis:                      12.852   Cond. No.                         24.1\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\n# Plot the orginal data (as before)\nsns.scatterplot(x='rating', y='criminal_incidents', alpha=0.3, data=df, s=100)\n\n# Generate and plot the model fit line\nxs = np.arange(df['rating'].min(), df['rating'].max())\nys = 9.4110 * xs + 8.0928\nplt.plot(xs, ys, '--k', linewidth=4, label='Model')\n\nplt.xlabel('Yelp Ratings')\nplt.ylabel('Number of Criminal Incidents')\nplt.title('Relationship between Number of Criminal Incidents and Yelp Ratings of Public Park in San Diego')\nplt.legend();\n\n\n\n\n\n\n\n\nThe model suggests that there may be a small correlation between the number of criminal incidents on a park’s block and the yelp rating of that park. The higher the Yelp rating, the higher the criminal incidents.\n\n#create thje model\noutcome, predictors = patsy.dmatrices('criminal_incidents ~ review_count', df)\nmod = sm.OLS(outcome, predictors)\n\n## fit the model\nres = mod.fit()\n\n## look at the results\nprint(res.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:     criminal_incidents   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.012\nMethod:                 Least Squares   F-statistic:                  0.003176\nDate:                Thu, 15 Aug 2024   Prob (F-statistic):              0.955\nTime:                        19:50:52   Log-Likelihood:                -479.55\nNo. Observations:                  88   AIC:                             963.1\nDf Residuals:                      86   BIC:                             968.1\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n================================================================================\n                   coef    std err          t      P&gt;|t|      [0.025      0.975]\n--------------------------------------------------------------------------------\nIntercept       43.6183      6.819      6.396      0.000      30.062      57.175\nreview_count    -0.0043      0.077     -0.056      0.955      -0.157       0.148\n==============================================================================\nOmnibus:                       75.887   Durbin-Watson:                   2.038\nProb(Omnibus):                  0.000   Jarque-Bera (JB):              459.500\nSkew:                           2.841   Prob(JB):                    1.66e-100\nKurtosis:                      12.645   Cond. No.                         100.\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\n# Plot the orginal data (as before)\nsns.scatterplot(x='review_count', y='criminal_incidents', alpha=0.3, data=df, s=100)\n\n# Generate and plot the model fit line\nxs = np.arange(df['review_count'].min(), df['review_count'].max())\nys = 0.0820 * xs + 40.6137\nplt.plot(xs, ys, '--k', linewidth=4, label='Model')\n\nplt.xlabel('Number of Yelp Reviews')\nplt.ylabel('Number of Criminal Incidents')\nplt.title('Relationship between Number of Criminal Incidents and Yelp Ratings Public Parks in San Diego')\nplt.legend();\n\n\n\n\n\n\n\n\nThe model suggests that there may be a larger positive correlation between the number of Yelp reviews and the number of criminal incidents on a park’s block. The higher the number of Yelp reviews, the higher the criminal incidents."
  }
]